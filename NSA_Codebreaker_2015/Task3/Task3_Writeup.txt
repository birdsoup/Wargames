Wow...where to begin. I think this one took ~ days, a total of 25+ hrs
The goal of this task was to reverse engineer the encryption process and submit a file that encrypts the message "Sir, Good news! We have developed a capability to encode secret messages to help with OPERATION olqoa3pamgdsayu8xjy3. We are ready for our final tasking. VR, Codebreaker 3473009"

The actual decryption happens inside tier2(). First it parses the file. Observing the inputs to several functions(such as SHA384_Update) seems to show that the message is completely decoded to plaintext from the msg file, so all that RSA, Base64Decode, and SHA384 stuff may seem puzzling. The plaintext message is passed into SHA384_Update. This message was actually stored in a buffer that is located on the heap, and its contents were copied there from the stack. By putting a watchpoint on the address of the stack buffer that stores the message, we can see where and how the buffer is being filled. We say that, in the decryption algorithm, each letter were formed by first adding 64, then 8, 4, etc until it reached its final ASCII value. A closer look at the algorithm also shoes that this only happens when the parser encounters a white space, and also that only tabs (ASCII 9) and whitepsace (ASCII 32) seems to have any effect on the plaintext. So I go back into VIM and force it to show all whitespaces and tabs, and it instantly became clear that this was some sort of tabs/whitespace encoding. As it turns out, each letter is stored in its binary format (using ASCII encoding), where a <space> = 1 and <tabs> = 0. I used an online translator to translate string to binary, and wrote a simple python script to turn all the binaries into tabs/spaces and appended it to the file. 

However, a closer look at the actual data being decrypted shows that there seems to be more than just the plaintext message. Before the plaintext there were 7 characters, that I later found out is used for the header. Inside the header contains information about how long the plaintext message is, as well as how long the signature is. So I had to change the header so that it matches the new plaintext message length. The signature followed the message. The signature was, by far, the most puzzling, frustrating, and time consuming part. 

The "signature" is actually a base64 encoding of an RSA signature on the digest of the plaintext. I searched up the encryption, encoding, and hashing schemes used. They used RSA encryption, SHA384 hashing, and Base64 encoding. RSA_verify seems to be the function that determines whether or not your message was valid or not. A close inspection to the parameters of RSA_verify shows that passed in was the type, digest, digest length, signature, signature length, and RSA pointer. By searching up RSA_verify it became very clear what I had to do. I found the function RSA_sign, which provides me the signature I need for RSA_verify to pass. The digest was simply a SHA384 hash of the plaintext that was filled in during SHA_Update and SHA_Final. So, now I have the information that I need to create my signature. I have the private key and digest, so I passed those into RSA_sign and got the signature. However, the "signature" was first decoded in the decryption process, which means I need to encode it in base64 first. Here was where it was extremely frustrating as I was unfamiliar with how Base64 works. I had the correct signature, but I couldn't for the life of me find out how to encode/decode using the Openssl C library. The first thing I noticed was that my encoding was only 172 bytes, whereas the sample from tier1_msg.txt had 175. However, that shouldn't be since they both originated from a digest (48 bytes in SHA384), which is the same length, and RSA signatures should all be the same length as well (128 bytes). In addition, BIO_read kept returning 0 for unknown reasons. What was kinda fishy was the BIO_set_flags option where you could tell it to ignore new lines. This turned out to be very important. I downloaded an encoder and decoder online and in there was a comment saying that the NL flag was to tell the decoder not to flush the buffer every time it encountered a new line. However the decoder they used did not set the flag. Eventually, I took another look at the sample encoded signature from tier1_msg.txt and noticed that there was a newline character stuck in every 76 charcters. Like a lightbulb, everything became extremely clear. The difference in my length and the reference (172 vs 175) originated from these new line characters stuck in. The reason why the online decoder could decode my msg, but the executable couldn't, was because of the NL flag. I simply stuck in a newline at the exact character positions as the reference and changed the header size to show 175 length for signature, and it worked. 